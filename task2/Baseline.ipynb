{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5H-fHa7PtbG",
        "outputId": "d747a0fc-249e-4cdd-dbf4-665a193d7311"
      },
      "id": "Z5H-fHa7PtbG",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/OCR_HW/task2/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9CFlO3EkQVnB",
        "outputId": "b5245f60-f07d-4858-f09c-0cd11f51ef04"
      },
      "id": "9CFlO3EkQVnB",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/OCR_HW/task2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "9f37abdd",
      "metadata": {
        "id": "9f37abdd"
      },
      "outputs": [],
      "source": [
        "from data_reader import Vocabulary, HWDBDatasetHelper, ArchivedHWDBReader\n",
        "\n",
        "# your path to data\n",
        "train_path = '/content/drive/MyDrive/CASIA HWDB/HWDBTrain/Images.zip'\n",
        "test_path = '/content/drive/MyDrive/CASIA HWDB/HWDBTest/Images.zip'\n",
        "gt_path = './gt.txt'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Веса модели:\n",
        "# https://drive.google.com/file/d/1xCo1ET1y6ZKEqGLdIlkuYygVHtvg9mzy/view?usp=sharing"
      ],
      "metadata": {
        "id": "GI-feDDlNtlz"
      },
      "id": "GI-feDDlNtlz",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "2042614e",
      "metadata": {
        "id": "2042614e"
      },
      "source": [
        "# Simple CNN baseline\n",
        "\n",
        "pytorch is required for this baseline implementation\n",
        "\n",
        "## Baseline method\n",
        "\n",
        "- Naively resize to 32x32 (DON'T DO THIS IN YOUR WORK, try to save geometry somehow, it is important)\n",
        "- Train LeNet-like CNN\n",
        "- Enjoy :)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "73d8b167",
      "metadata": {
        "id": "73d8b167"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f81f84ab",
      "metadata": {
        "id": "f81f84ab"
      },
      "source": [
        "### Data tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "f7f882df",
      "metadata": {
        "id": "f7f882df"
      },
      "outputs": [],
      "source": [
        "train_reader = ArchivedHWDBReader(train_path)\n",
        "train_reader.open()\n",
        "train_helper = HWDBDatasetHelper(train_reader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "35cf8784",
      "metadata": {
        "id": "35cf8784"
      },
      "outputs": [],
      "source": [
        "train_helper, val_helper = train_helper.train_val_split()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "92eb367e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92eb367e",
        "outputId": "7ea27b36-4c94-49c7-c61f-d10085032271"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2578433, 644609)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "train_helper.size(), val_helper.size()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch import nn\n",
        "\n",
        "class HWDBDataset(Dataset):\n",
        "    def __init__(self, helper: HWDBDatasetHelper):\n",
        "        self.helper = helper\n",
        "    \n",
        "    def __len__(self):\n",
        "        return self.helper.size()\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        im, label = self.helper.get_item(idx)\n",
        "\n",
        "        ratio = 128.0/max(im.shape[:2])\n",
        "        new_size = tuple([int(x * ratio) for x in im.shape[:2]])\n",
        "        im = cv2.resize(im, (new_size[1], new_size[0]))\n",
        "\n",
        "        new_im = cv2.copyMakeBorder(im, (128.0 - new_size[0])//2, \n",
        "                                    (128.0 - new_size[0]) - ((128.0 - new_size[0])//2), \n",
        "                                    (128.0 - new_size[1])//2, \n",
        "                                    (128.0 - new_size[1]) - ((128.0 - new_size[1])//2), cv2.BORDER_CONSTANT,\n",
        "            value=[255, 255, 255])\n",
        "\n",
        "        im_rgb = cv2.cvtColor(new_im, cv2.COLOR_GRAY2RGB)\n",
        "        return (im_rgb - 127.5) / 255., label"
      ],
      "metadata": {
        "id": "aco1dL98F5xf"
      },
      "id": "aco1dL98F5xf",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9e0c381",
      "metadata": {
        "id": "b9e0c381"
      },
      "outputs": [],
      "source": [
        "train_dataset = HWDBDataset(train_helper)\n",
        "val_dataset = HWDBDataset(val_helper)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7b6636f",
      "metadata": {
        "id": "e7b6636f"
      },
      "source": [
        "### Model & training"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import models\n",
        "from pytorch_metric_learning import losses"
      ],
      "metadata": {
        "id": "ZkEbyhQuGf7g"
      },
      "id": "ZkEbyhQuGf7g",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.resnet18(pretrained=True)\n",
        "in_features_size = model.fc.in_features\n",
        "model.fc = nn.Linear(in_features_size, 1024)\n",
        "model.eval()\n",
        "model = model.cuda()"
      ],
      "metadata": {
        "id": "Kx1uEwpzGNXx"
      },
      "id": "Kx1uEwpzGNXx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c9fe9f2",
      "metadata": {
        "id": "1c9fe9f2"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=512, shuffle=True, drop_last=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=2048, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = losses.ArcFaceLoss(num_classes=train_helper.vocabulary.num_classes(), embedding_size=1024).to(torch.device('cuda'))\n",
        "optim_loss = torch.optim.Adam(loss_fn.parameters(), lr=0.0001)\n",
        "optim = torch.optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "YtwFUQENGnnY"
      },
      "id": "YtwFUQENGnnY",
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "def run_validation(val_loader: DataLoader, model: nn.Module, loss_fn, n_steps=None):\n",
        "    model.eval()\n",
        "    n_good = 0\n",
        "    n_all = 0\n",
        "    wrapper = lambda x: x\n",
        "    if n_steps is None:\n",
        "        n_steps = len(val_loader)\n",
        "        wrapper = tqdm\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for batch, (X, y) in enumerate(wrapper(val_loader)):\n",
        "            if batch == n_steps:\n",
        "                break\n",
        "            logits = loss_fn.get_logits(model(torch.swapaxes(X, 1, 3).to(torch.float32).cuda()))\n",
        "            classes = torch.argmax(logits, dim=1).cpu().numpy()\n",
        "            n_good += sum(classes == y.cpu().numpy())\n",
        "            n_all += len(classes)\n",
        "    \n",
        "    return n_good / n_all\n",
        "\n",
        "\n",
        "def train_epoch(train_loader: DataLoader, val_loader: DataLoader, model: nn.Module, optim, optim_loss, loss_fn):\n",
        "    for batch, (X, y) in enumerate(tqdm(train_loader)):\n",
        "        model.train()\n",
        "        logits = model(torch.swapaxes(X, 1, 3).to(torch.float32).cuda())\n",
        "\n",
        "        loss = loss_fn(logits, y.to(torch.long).cuda())\n",
        "        \n",
        "        optim.zero_grad()\n",
        "        optim_loss.zero_grad()\n",
        "        loss.backward()\n",
        "        optim_loss.step()\n",
        "        optim.step()"
      ],
      "metadata": {
        "id": "tnWHHiYwGnrT"
      },
      "id": "tnWHHiYwGnrT",
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(3):\n",
        "    print(f'Epoch {epoch}:')\n",
        "    train_epoch(train_loader, val_loader, model, optim, optim_loss, loss_fn)\n",
        "    accuracy = run_validation(val_loader, model, loss_fn)\n",
        "    print(f'accuracy: {accuracy}')\n",
        "    torch.save(model.state_dict(), f'resnet18_epoch_{epoch}.pth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0KQYbN2IGw2_",
        "outputId": "1c811a0d-03c7-4ee8-bd43-feeabebc1eef"
      },
      "id": "0KQYbN2IGw2_",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 528/5036 [18:01<2:47:26,  2.23s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_o_L1F-dGw5l"
      },
      "id": "_o_L1F-dGw5l",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "msVHW9N0Gnt4"
      },
      "id": "msVHW9N0Gnt4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "1de4c7b6",
      "metadata": {
        "id": "1de4c7b6"
      },
      "source": [
        "### Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.resnet18(pretrained=True)\n",
        "in_features_size = model.fc.in_features\n",
        "model.fc = nn.Linear(in_features_size, 1024)"
      ],
      "metadata": {
        "id": "uXgRE0Lhi3D2"
      },
      "id": "uXgRE0Lhi3D2",
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('resnet18_epoch_0.pth', map_location=torch.device('cpu')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iRiZqt-wgFIq",
        "outputId": "5ffb982d-40a1-4c0d-a423-193077e9b34b"
      },
      "id": "iRiZqt-wgFIq",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "id": "rMaNyv_-icS7"
      },
      "id": "rMaNyv_-icS7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "73dd6418",
      "metadata": {
        "id": "73dd6418"
      },
      "outputs": [],
      "source": [
        "test_path = r'/content/drive/MyDrive/CASIA HWDB/HWDBTest/Images.zip'\n",
        "pred_path = './pred.txt'\n",
        "\n",
        "test_reader = ArchivedHWDBReader(test_path)\n",
        "test_reader.open()\n",
        "test_helper = HWDBDatasetHelper(test_reader, prefix='Test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "71d47be7",
      "metadata": {
        "id": "71d47be7"
      },
      "outputs": [],
      "source": [
        "test_dataset = HWDBDataset(test_helper)\n",
        "test_loader = DataLoader(test_dataset, batch_size=2048, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "0304466b",
      "metadata": {
        "id": "0304466b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce32b6fa-7a07-42aa-fc96-deb08944cd98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 380/380 [6:00:39<00:00, 56.95s/it]\n"
          ]
        }
      ],
      "source": [
        "preds = []\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for X, _ in tqdm(test_loader):\n",
        "        logits = loss_fn.get_logits(model(torch.swapaxes(X, 1, 3).to(torch.float32)))\n",
        "        classes = torch.argmax(logits, dim=1).numpy()\n",
        "        preds.extend(classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "34ee1630",
      "metadata": {
        "id": "34ee1630"
      },
      "outputs": [],
      "source": [
        "with open(pred_path, 'w') as f_pred:\n",
        "    for idx, pred in enumerate(preds):\n",
        "        name = test_helper.namelist[idx]\n",
        "        cls = train_helper.vocabulary.class_by_index(pred)\n",
        "        print(name, cls, file=f_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf74d797",
      "metadata": {
        "id": "bf74d797"
      },
      "outputs": [],
      "source": [
        "!python -m cource_ocr_t2.evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73f5d06d",
      "metadata": {
        "id": "73f5d06d"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.3"
    },
    "colab": {
      "name": "Baseline.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}